{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgojiqdMXZ8H"
   },
   "source": [
    "# Problem 1 (10 pts):\n",
    "\n",
    "From Maximum Likelihood to Cross-Entropy Loss\n",
    "Learning Objectives: Connect probability theory to loss functions, understand why cross-entropy emerges naturally.\n",
    "\n",
    "Part A: Binary Classification Loss Derivation\n",
    "\n",
    "Setup: We have $n$ data points $\\{ (x_i, y_i) \\}_{i=1}^n$ where $x_i \\in \\mathbb{R}^d$ and $y_i \\in \\{ 0, 1 \\}$. Assume your model outputs the probability of class 1 as $p_i = p(y_i = 1 \\mid x_i) = \\sigma(w^T x_i + b)$ where $w \\in \\mathbb{R}^d$, $b \\in \\mathbb{R}$, and $\\sigma(z)$ is the sigmoid function $\\sigma(z) = 1 / (1 + e^{-z})$.\n",
    "\n",
    "1. Derive from MLE:\n",
    "    * Write the likelihood function for the dataset\n",
    "    * Take the log-likelihood\n",
    "    * Show that maximizing log-likelihood = minimizing binary cross-entropy\n",
    "    * Bonus (5 pts): Derive the gradient and show it has the nice form: $\\nabla_w BCE = X^T(p - y)$\n",
    "\n",
    "Part B: Extension to Multi-class\n",
    "\n",
    "1. Softmax derivation: Extend to $K$ classes using softmax function\n",
    "    * Likelihood\n",
    "    * Log-likelihood\n",
    "    * Maximizing log-likelihood = minimizing categorical cross-entropy\n",
    "\n",
    "Part C: Implement dependencies in `hw1_impl.py` for function `problem_1_part_c` in `hw1_script.py`. You will implement both binary and multi-class cross-entropy from scratch. You will compare your implementation with `sklearn.metrics.log_loss`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer: Problem 1, Part A\n",
    "## 1. Likelihood Function\n",
    "\n",
    "Each $y_i$ follows a Bernoulli distribution with parameter $p_i$:\n",
    "\n",
    "$$\n",
    "p(y_i \\mid x_i) = p_i^{y_i}(1 - p_i)^{1 - y_i}.\n",
    "$$\n",
    "\n",
    "Assuming i.i.d. data, the likelihood over the dataset is:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(w,b)\n",
    "=\n",
    "\\prod_{i=1}^n\n",
    "p_i^{y_i}(1 - p_i)^{1 - y_i}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Log-Likelihood\n",
    "\n",
    "Taking logs:\n",
    "\n",
    "$$\n",
    "\\log \\mathcal{L}(w,b)\n",
    "=\n",
    "\\sum_{i=1}^n\n",
    "\\left[\n",
    "y_i \\log p_i\n",
    "+\n",
    "(1 - y_i)\\log(1 - p_i)\n",
    "\\right].\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Maximizing Log-Likelihood = Minimizing Binary Cross-Entropy\n",
    "\n",
    "Maximizing $\\log \\mathcal{L}$ is equivalent to minimizing the negative log-likelihood:\n",
    "\n",
    "$$\n",
    "-\\log \\mathcal{L}(w,b)\n",
    "=\n",
    "\\sum_{i=1}^n\n",
    "\\left[\n",
    "- y_i \\log p_i\n",
    "-\n",
    "(1 - y_i)\\log(1 - p_i)\n",
    "\\right].\n",
    "$$\n",
    "\n",
    "This is the same as **binary cross-entropy (BCE)** objective.\n",
    "\n",
    "$$\n",
    "\\mathrm{BCE}(w,b)\n",
    "=\n",
    "\\frac{1}{n}\n",
    "\\sum_{i=1}^n\n",
    "\\left[\n",
    "- y_i \\log p_i\n",
    "-\n",
    "(1 - y_i)\\log(1 - p_i)\n",
    "\\right].\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\n",
    "\\arg\\max_{w,b} \\log \\mathcal{L}(w,b)\n",
    "=\n",
    "\\arg\\min_{w,b} \\mathrm{BCE}(w,b).\n",
    "$$\n",
    "\n",
    "## Bonus — Gradient Derivation\n",
    "\n",
    "Define:\n",
    "\n",
    "- $z_i = w^\\top x_i + b$\n",
    "- $p_i = \\sigma(z_i)$\n",
    "\n",
    "Let:\n",
    "\n",
    "- $X \\in \\mathbb{R}^{n \\times d}$ contain rows $x_i^\\top$\n",
    "- $y \\in \\mathbb{R}^n$ contain entries $y_i$\n",
    "- $p \\in \\mathbb{R}^n$ contain entries $p_i$\n",
    "\n",
    "Using the sum version of BCE:\n",
    "\n",
    "$$\n",
    "\\mathrm{BCE}_{\\text{sum}}\n",
    "=\n",
    "\\sum_{i=1}^n\n",
    "\\left[\n",
    "- y_i \\log p_i\n",
    "-\n",
    "(1 - y_i)\\log(1 - p_i)\n",
    "\\right].\n",
    "$$\n",
    "\n",
    "A key simplification occurs:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial z_i}\n",
    "=\n",
    "p_i - y_i.\n",
    "$$\n",
    "\n",
    "Using the chain rule $\\frac{\\partial z_i}{\\partial w} = x_i$, we obtain:\n",
    "\n",
    "$$\n",
    "\\nabla_w \\mathrm{BCE}_{\\text{sum}}\n",
    "=\n",
    "\\sum_{i=1}^n (p_i - y_i) x_i\n",
    "=\n",
    "X^\\top (p - y).\n",
    "$$\n",
    "\n",
    "If using the mean BCE:\n",
    "\n",
    "$$\n",
    "\\nabla_w \\mathrm{BCE}\n",
    "=\n",
    "\\frac{1}{n} X^\\top (p - y).\n",
    "$$\n",
    "\n",
    "Similarly,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathrm{BCE}_{\\text{sum}}}{\\partial b}\n",
    "=\n",
    "\\sum_{i=1}^n (p_i - y_i).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Answer:  Problem 1, Part B\n",
    "\n",
    "Now extend to $K$ classes.\n",
    "\n",
    "Each label is one-hot encoded:\n",
    "\n",
    "$$\n",
    "y_i \\in \\{0,1\\}^K,\n",
    "\\quad\n",
    "\\sum_{k=1}^K y_{ik} = 1.\n",
    "$$\n",
    "\n",
    "Model parameters:\n",
    "\n",
    "- $W \\in \\mathbb{R}^{d \\times K}$\n",
    "- $b \\in \\mathbb{R}^K$\n",
    "\n",
    "Logits:\n",
    "\n",
    "$$\n",
    "o_i = W^\\top x_i + b,\n",
    "\\quad\n",
    "o_{ik} = (W^\\top x_i + b)_k.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Softmax Probabilities\n",
    "\n",
    "$$\n",
    "p_{ik}\n",
    "=\n",
    "\\frac{\\exp(o_{ik})}\n",
    "{\\sum_{j=1}^K \\exp(o_{ij})}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Likelihood\n",
    "\n",
    "For one example:\n",
    "\n",
    "$$\n",
    "p(y_i \\mid x_i)\n",
    "=\n",
    "\\prod_{k=1}^K p_{ik}^{y_{ik}}.\n",
    "$$\n",
    "\n",
    "Dataset likelihood:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(W,b)\n",
    "=\n",
    "\\prod_{i=1}^n\n",
    "\\prod_{k=1}^K\n",
    "p_{ik}^{y_{ik}}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Log-Likelihood\n",
    "\n",
    "$$\n",
    "\\log \\mathcal{L}(W,b)\n",
    "=\n",
    "\\sum_{i=1}^n\n",
    "\\sum_{k=1}^K\n",
    "y_{ik} \\log p_{ik}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Maximizing Log-Likelihood = Minimizing Categorical Cross-Entropy\n",
    "\n",
    "Negative log-likelihood:\n",
    "\n",
    "$$\n",
    "-\\log \\mathcal{L}(W,b)\n",
    "=\n",
    "\\sum_{i=1}^n\n",
    "\\sum_{k=1}^K\n",
    "- y_{ik} \\log p_{ik}.\n",
    "$$\n",
    "\n",
    "This is the **categorical cross-entropy** loss:\n",
    "\n",
    "$$\n",
    "\\mathrm{CE}(W,b)\n",
    "=\n",
    "\\frac{1}{n}\n",
    "\\sum_{i=1}^n\n",
    "\\sum_{k=1}^K\n",
    "- y_{ik} \\log p_{ik}.\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\n",
    "\\arg\\max_{W,b} \\log \\mathcal{L}(W,b)\n",
    "=\n",
    "\\arg\\min_{W,b} \\mathrm{CE}(W,b).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvdT93egXiKT"
   },
   "source": [
    "# Problem 2 (10 pts): Normal Equations vs. Gradient Descent - A Computational Study\n",
    "Learning Objectives: Understand trade-offs between analytical and iterative solutions.\n",
    "\n",
    "Implement dependencies in `hw1_impl.py` for function `problem_2` in `hw1_script.py`.\n",
    "\n",
    "Analysis Tasks:\n",
    "\n",
    "1. Answer this question. Memory Usage: When does the normal equation become impractical?\n",
    "2. Conditioning: What happens when $X^TX$ is nearly singular? Add ridge regularization.\n",
    "3. Report: When would you choose each method in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer: Problem 2\n",
    "\n",
    "## 1) Memory Usage — When does the normal equation become impractical?\n",
    "\n",
    "The NE method forms and solves the system\n",
    "$$\n",
    "(X_{\\text{aug}}^\\top X_{\\text{aug}}) W = X_{\\text{aug}}^\\top Y,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "X_{\\text{aug}}^\\top X_{\\text{aug}} \\in \\mathbb{R}^{(d+1)\\times(d+1)}.\n",
    "$$\n",
    "\n",
    "Key scaling facts (dense case):\n",
    "\n",
    "- **Memory** to store $X_{\\text{aug}}^\\top X_{\\text{aug}}$ is $O(d^2)$.\n",
    "- **Time** to form $X_{\\text{aug}}^\\top X_{\\text{aug}}$ is $O(nd^2)$.\n",
    "- **Time** to solve the linear system is $O(d^3)$ (typical direct methods).\n",
    "\n",
    "Therefore, the normal equation becomes impractical primarily when the **feature dimension $d$ is large**, because:\n",
    "- storing a dense $(d+1)\\times(d+1)$ matrix becomes memory-heavy,\n",
    "- the $O(d^3)$ solve becomes prohibitively slow.\n",
    "\n",
    "By contrast, GD avoids $d^2$ storage and instead uses repeated matrix–vector/matrix–matrix products:\n",
    "- each iteration costs roughly $O(ndm)$,\n",
    "- memory is dominated by storing $X_{\\text{aug}}$ and $W$ (and possibly history).\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Conditioning — What happens when $X^\\top X$ is nearly singular? Add ridge regularization.\n",
    "\n",
    "When $X_{\\text{aug}}^\\top X_{\\text{aug}}$ is **singular** or **ill-conditioned** (nearly singular), this typically occurs due to:\n",
    "- multicollinearity (highly correlated features),\n",
    "- redundant features (linear dependence),\n",
    "- $d \\ge n$ (rank deficiency),\n",
    "- low effective rank.\n",
    "\n",
    "Consequences for NE:\n",
    "- solving becomes numerically unstable,\n",
    "- small perturbations in data can produce large changes in $W$,\n",
    "- coefficients can blow up, harming generalization.\n",
    "\n",
    "### Ridge regularization (as implemented)\n",
    "\n",
    "Ridge modifies the system to:\n",
    "$$\n",
    "\\left(X_{\\text{aug}}^\\top X_{\\text{aug}} + \\lambda R\\right) W = X_{\\text{aug}}^\\top Y,\n",
    "$$\n",
    "where $R$ is identity except bias is not regularized:\n",
    "$$\n",
    "R = I_{d+1}, \\quad R_{00}=0.\n",
    "$$\n",
    "\n",
    "Effects:\n",
    "- adds $\\lambda$ to the eigenvalues associated with weight directions (not the bias),\n",
    "- makes the matrix better conditioned (and typically invertible),\n",
    "- shrinks weights, reducing variance and improving stability.\n",
    "\n",
    "---\n",
    "\n",
    "## 3) When would you choose each method in practice?\n",
    "\n",
    "### Choose Normal Equations (NE) when:\n",
    "- $d$ is small to moderate (so $d^2$ memory and $d^3$ time are manageable),\n",
    "- you want a one-shot, deterministic solve,\n",
    "- conditioning is acceptable, or ridge is applied,\n",
    "- you can afford forming $X_{\\text{aug}}^\\top X_{\\text{aug}}$.\n",
    "\n",
    "### Choose Gradient Descent (GD) when:\n",
    "- $d$ is large (NE becomes memory/time prohibitive),\n",
    "- $n$ is very large and you want iterative/streaming optimization,\n",
    "- the data is sparse (GD can exploit sparsity better than dense $X^\\top X$),\n",
    "- you anticipate extending beyond linear models (same optimization machinery applies),\n",
    "- you can tolerate approximate solutions and control trade-offs via iterations and learning rate.\n",
    "\n",
    "---\n",
    "\n",
    "## Core Trade-off Summary\n",
    "\n",
    "- NE is an **analytic/direct** approach: fast and exact for small $d$, but scales poorly with $d$ due to $O(d^2)$ memory and $O(d^3)$ solve time.\n",
    "- GD is an **iterative/computational** approach: scales to large problems via repeated $O(nd)$-type operations, but depends on convergence behavior (learning rate, iterations, conditioning).\n",
    "- Ill-conditioning harms both methods, but ridge regularization directly stabilizes NE (and typically improves optimization geometry for GD as well)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6eGQF_5XeNY"
   },
   "source": [
    "# Problem 3 (10 pts): SGD Exploration - Escaping Local Minima (Extended)\n",
    "Learning Objectives: Understand SGD's stochastic nature and hyperparameter effects.\n",
    "\n",
    "Due to history, there is no Part A.\n",
    "\n",
    "Part B: Implement dependencies in `hw1_impl.py` for functions `problem_3_part_b` and `problem_3_part_c` in `hw1_script.py`.\n",
    "\n",
    "Part D: Analysis Questions\n",
    "\n",
    "1. What batch size gives the best exploration vs. exploitation trade-off?\n",
    "2. How does the \"escape probability\" change with learning rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3, Part D\n",
    "\n",
    "We ignore Parts A–C per the prompt and focus only on the two analysis questions. The context is the “two-hole” (and optionally multi-modal) **loss landscape in parameter space** with SGD-like updates, where stochasticity is simulated via additive noise and an “escape” mechanism.\n",
    "\n",
    "In the provided implementation, the SGD step is:\n",
    "$$\n",
    "w \\leftarrow w - \\text{lr}\\,\\tilde{g}(w),\n",
    "$$\n",
    "where the stochastic gradient is modeled as\n",
    "$$\n",
    "\\tilde{g}(w) =\n",
    "\\begin{cases}\n",
    "g_{\\text{global}}(w) + \\epsilon & \\text{with probability } \\text{escape\\_chance},\\\\[4pt]\n",
    "g_{\\text{true}}(w) + \\epsilon & \\text{otherwise},\n",
    "\\end{cases}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "g_{\\text{true}}(w) = g_{\\text{local}}(w) + g_{\\text{global}}(w), \n",
    "\\qquad\n",
    "\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I).\n",
    "$$\n",
    "\n",
    "Critically, batch size affects the initial noise scale as implemented:\n",
    "$$\n",
    "\\sigma \\equiv \\text{noise\\_scale} = \\frac{\\text{initial\\_noise}}{\\sqrt{\\text{batch\\_size}}},\n",
    "$$\n",
    "and the noise decays over time:\n",
    "$$\n",
    "\\sigma \\leftarrow \\sigma \\cdot \\text{noise\\_decay} \\quad \\text{each iteration.}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## D1) What batch size gives the best exploration vs. exploitation trade-off?\n",
    "\n",
    "**Core relationship:** in this simulation, larger batch size reduces stochasticity:\n",
    "$$\n",
    "\\text{batch\\_size} \\uparrow \\;\\Rightarrow\\; \\sigma \\downarrow.\n",
    "$$\n",
    "\n",
    "### Small batch sizes (high noise)\n",
    "- **Pros (exploration):** Higher $\\sigma$ increases the chance of *escaping* shallow basins / local minima because random perturbations can push $w$ over “barriers” between attraction basins.\n",
    "- **Cons (exploitation):** High noise prevents fine convergence; even near a minimum, updates jitter and can bounce out or hover without settling, especially if noise remains nontrivial.\n",
    "\n",
    "### Large batch sizes (low noise)\n",
    "- **Pros (exploitation):** Lower $\\sigma$ yields stable, smooth descent; convergence is cleaner and more consistent once you’re in a good basin.\n",
    "- **Cons (exploration):** Low noise makes escapes rare; trajectories become “deterministic” and can get trapped in the nearest local minimum determined by the start point and geometry.\n",
    "\n",
    "### Best trade-off (answer)\n",
    "The best exploration/exploitation balance is typically achieved by a **moderate batch size**:\n",
    "- not so small that noise dominates and prevents convergence,\n",
    "- not so large that the process becomes nearly deterministic and gets stuck.\n",
    "\n",
    "In terms of the implemented scaling $\\sigma \\propto 1/\\sqrt{\\text{batch\\_size}}$, “moderate” means a batch size that makes $\\sigma$ large enough early on to cross basins, but small enough after decay to permit convergence. Practically, you’d see this in the heatmaps as:\n",
    "- relatively **high escape probability**,\n",
    "- **low best/mean loss** (finding the deeper minimum more often),\n",
    "- **reasonable convergence iterations** (not exploding due to jitter),\n",
    "- and runtime that’s not excessive.\n",
    "\n",
    "So, **choose mid-range batch sizes** (neither extreme) as the best trade-off in this experiment.\n",
    "\n",
    "---\n",
    "\n",
    "## D2) How does the “escape probability” change with learning rate?\n",
    "\n",
    "Here “escape probability” is measured empirically (e.g., `escaped = losses < thresh`) across trials. Learning rate affects escape in two opposing ways:\n",
    "\n",
    "### Regime 1: Learning rate too small\n",
    "- Steps are tiny:\n",
    "  $$\n",
    "  \\Delta w \\approx \\text{lr}\\,\\tilde{g}(w)\n",
    "  $$\n",
    "- Even with noise, movement per iteration is limited.\n",
    "- Result: it may take many steps to leave a basin; within a fixed iteration budget, **escape probability tends to be low**.\n",
    "\n",
    "### Regime 2: Learning rate moderate\n",
    "- Steps are large enough to traverse the landscape meaningfully.\n",
    "- Noise + gradient can push parameters across basin boundaries.\n",
    "- Result: **escape probability increases**, often substantially.\n",
    "\n",
    "### Regime 3: Learning rate too large\n",
    "- Updates can overshoot:\n",
    "  - bounce across regions without settling,\n",
    "  - become unstable and fail to converge,\n",
    "  - or ricochet between areas, sometimes missing the global basin even if “escaping” the local one.\n",
    "- Depending on the threshold definition, two outcomes occur:\n",
    "  - **escape probability may plateau or drop** (if instability prevents reaching sufficiently low loss),\n",
    "  - even if “movement” is large, **successful escapes to the deep minimum become less frequent**.\n",
    "\n",
    "### Net effect (answer)\n",
    "Escape probability typically shows a **non-monotonic** pattern with learning rate:\n",
    "- **low** at very small lr,\n",
    "- **higher** at moderate lr,\n",
    "- **worse or unstable** at overly large lr (sometimes decreasing in “successful escape” rate).\n",
    "\n",
    "In the heatmaps, this often appears as:\n",
    "- moderate learning rates yielding the best combination of high escape probability and low best/mean loss,\n",
    "- extreme high learning rates showing poor losses and inconsistent convergence iterations, even if trajectories move a lot.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "- **Best exploration vs. exploitation** in this setup comes from **moderate batch sizes**, because $\\sigma \\propto 1/\\sqrt{\\text{batch\\_size}}$ makes small batches too noisy and large batches too deterministic.\n",
    "- **Escape probability vs. learning rate** is typically **non-monotonic**: it rises from small lr to moderate lr, then worsens at overly large lr due to overshoot/instability and reduced “successful” convergence into the deep basin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9_VboSURl6f"
   },
   "source": [
    "# Problem 4 (10 pts): The Perceptron Problem - Understanding Linear Separability Limitations\n",
    "\n",
    "## What is a Perceptron?\n",
    "\n",
    "Based on our lecture, a **perceptron** is a binary classifier that makes predictions using a linear decision boundary. It consists of:\n",
    "\n",
    "- **Inputs**: A feature vector $x \\in \\mathbb{R}^d$\n",
    "- **Weights**: A weight vector $w \\in \\mathbb{R}^d$\n",
    "- **Bias**: A scalar bias term $b \\in \\mathbb{R}$\n",
    "- **Activation**: A step function (threshold function)\n",
    "\n",
    "The perceptron computes:\n",
    "$$ f(x) = \\text{step} (w^T x + b) $$\n",
    "\n",
    "Where the step function outputs:\n",
    "$$ \\text{step}(w^T x + b) = \\begin{cases}\n",
    "1 & \\text{if} \\quad w^T x + b \\geq 0 \\\\\n",
    "0 & \\text{if} \\quad w^T x + b < 0\n",
    "\\end{cases} $$\n",
    "\n",
    "The decision boundary is the hyperplane defined by $w^T x + b = 0$, which divides the input space into two regions.\n",
    "\n",
    "## The Fundamental Problem\n",
    "\n",
    "The perceptron suffers from a **critical limitation**: it can only solve **linearly separable** problems. This means it can only correctly classify data where the two classes can be perfectly separated by a single straight line (in 2D) or hyperplane (in higher dimensions).\n",
    "\n",
    "### The XOR Problem: A Classic Example\n",
    "\n",
    "The most famous demonstration of this limitation is the **XOR (Exclusive OR) problem**:\n",
    "\n",
    "| x₁ | x₂ | XOR Output |\n",
    "|----|----|------------|\n",
    "| 0  | 0  | 0          |\n",
    "| 0  | 1  | 1          |\n",
    "| 1  | 0  | 1          |\n",
    "| 1  | 1  | 0          |\n",
    "\n",
    "If you plot these four points:\n",
    "- Points (0,1) and (1,0) should be classified as class 1 (XOR = 1)\n",
    "- Points (0,0) and (1,1) should be classified as class 0 (XOR = 0)\n",
    "\n",
    "**No single straight line can separate these classes!** The pattern requires a non-linear decision boundary.\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "This limitation reveals why:\n",
    "\n",
    "1. **Single perceptrons are insufficient** for many real-world problems\n",
    "2. **We need non-linearity** in our models (like ReLU activation functions)\n",
    "3. **Multiple layers are essential** to create complex, non-linear decision boundaries\n",
    "4. **The XOR problem motivated** the development of multi-layer neural networks\n",
    "\n",
    "As we learned in our previous lecture, when we combine multiple ReLU neurons and stack them in layers, we can create complex, bent decision boundaries that can solve non-linearly separable problems like XOR.\n",
    "\n",
    "This historical limitation of the perceptron was so significant that it contributed to the \"AI winter\" of the 1970s, until researchers developed multi-layer networks with backpropagation in the 1980s.\n",
    "\n",
    "Learning Objectives\n",
    "\n",
    "1. Implement a perceptron from scratch to understand its mechanics\n",
    "2. Demonstrate why linear models fail on non-linearly separable data\n",
    "3. Visualize decision boundaries and their limitations\n",
    "4. Show how adding non-linear features can solve the problem\n",
    "\n",
    "Implement dependencies in `hw1_impl.py` for functions `problem_4` in `hw1_script.py`."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
